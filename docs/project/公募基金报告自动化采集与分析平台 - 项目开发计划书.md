# **公募基金报告自动化采集与分析平台 \- 项目开发计划书**

| 文档版本 | 修订日期 | 修订人 | 修订说明 |
| :---- | :---- | :---- | :---- |
| V1.1 | 2025年7月12日 | AI技术架构师 | 为各阶段添加详细的开发任务列表 |
| V1.0 | 2025年7月12日 | AI技术架构师 | 初始版本创建，定义技术栈、开发计划和规范 |

## **1\. 项目概述**

本开发计划书基于《公募基金报告自动化采集与分析平台PRD V1.0》，旨在为该项目的技术实现提供详细的蓝图和执行路径。本文档面向开发团队、项目经理和运维人员，将详细阐述技术架构选型、详细的开发排期、以及必须遵守的开发规范，特别是关于日志和测试的强制性要求。

**核心目标**：构建一个稳定、可扩展、易于维护的数据管道系统，确保数据采集的成功率和数据的准确性，同时保障系统自身的健康和可观测性。

## **2\. 技术架构与选型**

为满足PRD中定义的需求，我们选择以Python为核心的现代化技术栈，采用模块化的架构设计，确保各组件职责单一、易于扩展。

| 模块/领域 | 技术选型 | 选型理由 |
| :---- | :---- | :---- |
| **编程语言** | Python 3.10+ | 生态丰富，在数据处理、网络爬虫领域有成熟的库支持，社区活跃。 |
| **Web/API框架** | FastAPI | 高性能，支持异步IO，能有效提升爬虫和数据处理效率。自带数据校验和API文档，开发效率高。 |
| **数据爬取** | httpx | 现代化的HTTP客户端，支持同步和异步请求，与FastAPI无缝集成。 |
| **HTML/XML解析** | lxml / beautifulsoup4 | lxml性能极高，beautifulsoup4的API更友好，可结合使用。 |
| **XBRL解析** | arelle 或 自研解析器 | arelle是专业的开源XBRL处理工具。若其过于笨重，可基于lxml针对性地开发轻量级解析器。 |
| **任务调度与队列** | Celery \+ Redis | 业界标准的分布式任务队列。Celery负责任务的定义和调度（定时/手动），Redis作为Broker，高效、稳定。 |
| **数据库** | PostgreSQL 14+ | 功能强大的开源关系型数据库，对JSONB等非结构化数据支持良好，性能稳定可靠。 |
| **数据库ORM** | SQLAlchemy 2.0 \+ Alembic | SQLAlchemy是Python中最强大的ORM，提供灵活的数据库操作。Alembic用于数据库结构的版本管理和迁移。 |
| **原始文件存储** | MinIO | 高性能的开源对象存储，兼容Amazon S3接口，便于未来扩展或迁移至云端。 |
| **日志框架** | **Structlog** | **\[强制要求\]** 提供结构化的日志记录。相比标准库logging，其日志易于机器解析、查询和监控，是保障系统可观测性的基石。 |
| **测试框架** | **Pytest** | **\[强制要求\]** 功能强大、灵活且易于上手的测试框架。丰富的插件生态（如pytest-cov, pytest-asyncio）能满足所有测试需求。 |
| **容器化** | Docker / Docker Compose | 实现开发、测试、生产环境的一致性，简化部署和运维流程。 |
| **代码规范** | Black, isort, Flake8 | 自动化代码格式化和风格检查，保证代码一致性和可读性。 |

### **架构图**

graph TD  
    subgraph "调度与执行层"  
        A\[Celery Beat: 定时任务\] \--\> B{Redis: 任务队列};  
        C\[FastAPI: 手动任务API\] \--\> B;  
        D\[Celery Worker(s)\] \-- 拉取任务 \--\> B;  
    end

    subgraph "核心处理逻辑 (运行于Celery Worker)"  
        D \--\> E\[爬虫模块: httpx\];  
        E \--\> F\[目标网站: eid.csrc.gov.cn\];  
        E \--\> G\[Rate Limiter\];  
        E \--\> H\[数据解析模块\];  
        H \-- XBRL/HTML \--\> I\[arelle / lxml\];  
        I \--\> J\[数据提取与结构化\];  
    end

    subgraph "存储层"  
        J \--\> K\[SQLAlchemy ORM\];  
        K \--\> L\[PostgreSQL: 结构化数据\];  
        E \-- 下载原始文件 \--\> M\[MinIO: 对象存储\];  
        K \-- 存储文件路径 \--\> L;  
    end

    subgraph "监控与运维"  
        D \-- 写入日志 \--\> N\[Structlog\];  
        O\[Pytest: 单元/集成测试\] \-- 测试 \--\> D;  
        P\[Docker Compose\] \-- 管理 \--\> A & C & D & B & L & M;  
    end

    style F fill:\#f9f,stroke:\#333,stroke-width:2px

## **3\. 项目开发计划**

项目总周期预计为 **12周**，分为五个主要阶段。

| 阶段 | 周期 | 主要任务 (Task List) | 产出物 | 里程碑 |
| :---- | :---- | :---- | :---- | :---- |
| **第一阶段：基础架构与核心爬取** | **3周 (W1-W3)** | 1\. **环境与项目初始化 (W1)**\<br\> \- 初始化Git仓库，配置.gitignore和分支保护规则。\<br\> \- 使用Poetry或Pipenv管理Python依赖。\<br\> \- 搭建docker-compose.yml，编排PostgreSQL, Redis, MinIO服务。\<br\>2. **日志与测试集成 (W1)**\<br\> \- **配置Structlog**，定义JSON格式化输出，并编写日志使用规范文档。\<br\> \- **配置Pytest**，集成pytest-cov和pytest-asyncio，建立tests目录结构。\<br\> \- 配置CI流程（如GitHub Actions），自动运行代码规范检查和单元测试。\<br\>3. **数据库建模 (W2)**\<br\> \- 使用SQLAlchemy Core/ORM定义PRD中的所有数据表模型。\<br\> \- 初始化Alembic，生成第一个数据库版本迁移脚本。\<br\>4. **核心爬虫开发 (W2-W3)**\<br\> \- 实现一个爬虫类，负责与目标网站交互。\<br\> \- 实现获取报告列表的逻辑，能够处理分页。\<br\> \- 实现报告原始文件的下载逻辑，并存入MinIO。\<br\> \- 为爬虫模块编写单元测试，Mock掉httpx请求。 | \- 可运行的Docker环境\<br\>- 结构化的日志输出\<br\>- 基础测试用例\<br\>- 能够下载报告文件的脚本 | **环境搭建完成，核心爬取功能通过测试** |
| **第二阶段：数据解析与入库** | **3周 (W4-W6)** | 1\. **XBRL解析器研究与实现 (W4)**\<br\> \- 调研arelle库或手动解析XBRL的可行性，并做出技术选型。\<br\> \- 实现一个XBRLParser类，能够加载XBRL文件。\<br\>2. **关键数据提取 (W5)**\<br\> \- 编写函数，从解析后的XBRL中提取“资产配置表”。\<br\> \- 编写函数，提取“前十大重仓股”信息。\<br\> \- 编写函数，提取“行业配置”等其他关键数据。\<br\>3. **数据入库逻辑 (W6)**\<br\> \- 开发数据持久化服务，负责将解析出的结构化数据对象转换为数据库模型，并存入PostgreSQL。\<br\> \- 实现数据唯一性检查逻辑。\<br\>4. **编写解析器单元测试 (W4-W6)**\<br\> \- 寻找多个不同基金公司、不同年份的真实XBRL报告作为测试样本。\<br\> \- 为每个数据提取函数编写详细的单元测试，确保准确性。 | \- 可独立运行的解析模块\<br\>- 准确的结构化数据表\<br\>- 解析模块单元测试覆盖率 \> 80% | **首个完整报告成功解析并入库** |
| **第三阶段：任务调度与健壮性** | **2周 (W7-W8)** | 1\. **Celery集成 (W7)**\<br\> \- 配置Celery应用，连接到Redis Broker。\<br\> \- 将“爬取-解析-入库”的完整流程封装成一个Celery Task。\<br\> \- 配置Celery Beat，实现PRD中定义的定时调度规则。\<br\>2. **健壮性增强 (W8)**\<br\> \- 实现一个基于令牌桶或漏桶算法的Rate Limiter模块，并集成到爬虫中。\<br\> \- 在Celery Task中加入全局的try-except块，捕获异常并使用Structlog详细记录。\<br\> \- 实现任务失败后的自动重试机制（利用Celery自带功能）。\<br\>3. **集成测试 (W8)**\<br\> \- 编写端到端的集成测试，模拟一次完整的任务调度，验证所有模块协同工作正常。 | \- 自动化的数据采集任务\<br\>- 健壮的错误处理流程\<br\>- 端到端集成测试用例 | **自动化数据管道全流程打通** |
| **第四阶段：部署与API** | **2周 (W9-W10)** | 1\. **生产环境部署准备 (W9)**\<br\> \- 编写生产环境专用的Dockerfile，优化镜像大小和构建速度。\<br\> \- 编写docker-compose.prod.yml用于生产环境部署。\<br\> \- 将所有可配置项（数据库密码、API密钥等）移至环境变量或.env文件。\<br\>2. **数据查询API开发 (W10)**\<br\> \- 使用FastAPI设计并实现几个基础的数据查询接口（如：按基金代码查询最新持仓）。\<br\> \- 编写API的自动化测试。\<br\>3. **文档撰写 (W10)**\<br\> \- 撰写详细的《运维手册》，说明如何部署、监控、备份系统。\<br\> \- FastAPI自动生成API文档，补充必要的说明。 | \- 一键部署脚本\<br\>- 内部数据查询API\<br\>- 完善的开发与运维文档 | **系统准生产环境部署完成** |
| **第五阶段：验收与上线** | **2周 (W11-W12)** | 1\. **用户验收测试 (UAT) (W11)**\<br\> \- 邀请最终用户（研究员等）试用系统，验证数据准确性。\<br\> \- 收集反馈并修复期间发现的Bug。\<br\>2. **历史数据回补 (W11-W12)**\<br\> \- 开启爬虫，抓取过去3-5年的历史报告数据。\<br\> \- 监控回补过程，处理可能出现的各种异常情况。\<br\>3. **正式上线 (W12)**\<br\> \- 在服务器上正式部署生产环境。\<br\> \- 确认定时任务正常运行，进入持续监控和维护阶段。 | \- UAT测试报告\<br\>- 完整的历史数据库\<br\>- 稳定的线上运行系统 | **项目正式上线** |

## **4\. 开发规范与标准 (强制执行)**

所有开发人员必须无条件遵守以下规范，这将作为Code Review和合并请求(Pull Request)的强制检查项。

### **4.1. 版本控制**

* **分支模型**：采用 main (主分支) 和 develop (开发分支) 模型。所有新功能开发必须从 develop 创建新的 feature 分支。  
* **合并请求 (PR)**：任何代码都合入 develop 分支前，必须创建PR，并至少需要一名其他开发人员审查通过(Approve)。  
* **PR检查项**：PR必须关联到具体的需求或Bug，并且 **必须通过所有自动化测试(CI)**。

### **4.2. 日志规范 (Structlog)**

* **目标**：**杜绝 print() 语句**。所有运行时信息输出必须使用Structlog。  
* **结构化**：日志必须是JSON格式。每条日志都应包含时间戳、日志级别、日志信息，以及关键的上下文信息。  
* **上下文绑定**：在任务开始时，必须将关键上下文（如 task\_id, fund\_code, report\_year）绑定到logger，确保后续该任务的所有日志都自动携带这些信息。  
  \# 伪代码示例  
  log \= structlog.get\_logger()  
  log \= log.bind(task\_id="abc-123", fund\_code="000001")  
  log.info("task.started", report\_type="ANNUAL")

* **日志级别**：  
  * INFO: 关键业务流程节点（如任务开始/结束，文件下载成功）。  
  * WARNING: 可预期的、可自动恢复的异常（如网络抖动导致重试，某个非关键字段解析失败）。  
  * ERROR: 导致当前任务失败的严重错误（如XBRL文件结构性损坏，数据库连接失败）。  
  * DEBUG: 仅用于开发调试的详细信息，生产环境默认关闭。

### **4.3. 测试规范 (Pytest)**

* **目标**：保证代码质量，便于未来重构和维护。  
* **测试类型**：  
  * **单元测试**：针对单个函数或类进行测试，必须覆盖所有核心业务逻辑。使用mock来隔离外部依赖（如数据库、网络请求）。  
  * **集成测试**：测试多个模块之间的交互，如“解析器+数据库”的交互是否正确。  
* **测试覆盖率**：强制要求核心业务模块（解析、数据处理）的 **测试覆盖率不得低于80%**。CI流程将检查覆盖率报告。  
* **测试编写**：  
  * 每个feature分支在提交PR时，必须附带相应的测试用例。  
  * 测试用例应清晰、独立，断言明确。  
  * 积极使用pytest.mark.parametrize来覆盖多种输入场景。

**文档结束**