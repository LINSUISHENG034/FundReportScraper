#!/usr/bin/env python3
"""
å¹³å®‰åŸºé‡‘å…¨é‡æ•°æ®è§£æè„šæœ¬
Complete PingAn Fund data parser from HTML
"""

import sys
import re
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
from bs4 import BeautifulSoup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def parse_pingan_funds_html():
    """è§£æå¹³å®‰åŸºé‡‘HTMLæ•°æ®"""
    
    html_file = Path("data/pingan/å¹³å®‰åŸºé‡‘.md")
    
    if not html_file.exists():
        print(f"âŒ HTMLæ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
        return []
    
    print(f"ğŸ“‚ è¯»å–HTMLæ–‡ä»¶: {html_file}")
    
    # è¯»å–HTMLå†…å®¹
    with open(html_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    # ç§»é™¤markdownä»£ç å—æ ‡è®°
    html_content = html_content.replace('```', '')
    
    print(f"ğŸ“„ HTMLæ–‡ä»¶å¤§å°: {len(html_content)/1024:.1f} KB")
    
    # ä½¿ç”¨BeautifulSoupè§£æHTML
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # æŸ¥æ‰¾æ‰€æœ‰åŸºé‡‘è¡Œ
    fund_rows = soup.find_all('tr')
    print(f"ğŸ” æ‰¾åˆ° {len(fund_rows)} è¡Œæ•°æ®")
    
    funds_data = []
    
    for row in fund_rows:
        try:
            # æŸ¥æ‰¾åŸºé‡‘åç§°å’Œä»£ç 
            fund_name_cell = row.find('td', class_='fund-name')
            if not fund_name_cell:
                continue
            
            # æå–åŸºé‡‘åç§°å’Œä»£ç 
            fund_link = fund_name_cell.find('a')
            if not fund_link:
                continue
            
            # åŸºé‡‘åç§°åœ¨<br>æ ‡ç­¾å‰
            fund_name_text = fund_link.get_text()
            if '<br>' in str(fund_link):
                # åˆ†ç¦»åŸºé‡‘åç§°ï¼ˆå»æ‰<br>åçš„å†…å®¹ï¼‰
                fund_name = fund_name_text.split('\n')[0].strip() if '\n' in fund_name_text else fund_name_text.strip()
            else:
                fund_name = fund_name_text.strip()
            
            # åŸºé‡‘ä»£ç åœ¨<span>æ ‡ç­¾å†…
            code_span = fund_link.find('span')
            if not code_span:
                continue
            
            fund_code = code_span.get_text(strip=True)
            
            # éªŒè¯åŸºé‡‘ä»£ç æ ¼å¼ï¼ˆ6ä½æ•°å­—ï¼‰
            if not re.match(r'^\d{6}$', fund_code):
                continue
            
            # æŸ¥æ‰¾æ‰€æœ‰tdå…ƒç´ æ¥æå–å…¶ä»–æ•°æ®
            cells = row.find_all('td')
            if len(cells) < 6:
                continue
            
            # æå–åŸºé‡‘å‡€å€¼
            fund_value_span = cells[1].find('span', class_='fund-value')
            unit_nav = None
            nav_date = None
            
            if fund_value_span:
                unit_nav_text = fund_value_span.get_text(strip=True)
                try:
                    unit_nav = float(unit_nav_text)
                except:
                    unit_nav = None
                
                # æå–å‡€å€¼æ—¥æœŸ
                date_span = cells[1].find('span', title='å‡€å€¼æ—¥æœŸ')
                if date_span:
                    nav_date = date_span.get_text(strip=True)
            
            # æå–ç´¯è®¡å‡€å€¼
            cumulative_nav = None
            if len(cells) > 2:
                cumulative_nav_text = cells[2].get_text(strip=True)
                try:
                    cumulative_nav = float(cumulative_nav_text)
                except:
                    cumulative_nav = None
            
            # æå–æ—¥æ¶¨è·Œå¹…
            daily_change = None
            if len(cells) > 3:
                daily_change_text = cells[3].get_text(strip=True)
                if daily_change_text and daily_change_text != '--':
                    try:
                        daily_change = float(daily_change_text.replace('%', '')) / 100
                    except:
                        daily_change = None
            
            # æå–è¿‘ä¸€æœˆæ”¶ç›Šç‡
            one_month_return = None
            if len(cells) > 4:
                one_month_text = cells[4].get_text(strip=True)
                if one_month_text and one_month_text != '--':
                    try:
                        one_month_return = float(one_month_text.replace('%', '')) / 100
                    except:
                        one_month_return = None
            
            # æå–è¿‘ä¸€å¹´æ”¶ç›Šç‡
            one_year_return = None
            if len(cells) > 5:
                one_year_text = cells[5].get_text(strip=True)
                if one_year_text and one_year_text != '--':
                    try:
                        one_year_return = float(one_year_text.replace('%', '')) / 100
                    except:
                        one_year_return = None
            
            # æå–æˆç«‹ä»¥æ¥æ”¶ç›Šç‡
            since_inception_return = None
            if len(cells) > 6:
                inception_text = cells[6].get_text(strip=True)
                if inception_text and inception_text != '--':
                    try:
                        since_inception_return = float(inception_text.replace('%', '')) / 100
                    except:
                        since_inception_return = None
            
            # åˆ¤æ–­åŸºé‡‘ç±»å‹ï¼ˆåŸºäºåŸºé‡‘åç§°ï¼‰
            fund_type = determine_fund_type(fund_name)
            
            # æ„å»ºåŸºé‡‘æ•°æ®
            fund_data = {
                "fund_code": fund_code,
                "fund_name": fund_name,
                "fund_company": "å¹³å®‰åŸºé‡‘ç®¡ç†æœ‰é™å…¬å¸",
                "fund_type": fund_type,
                "unit_nav": unit_nav,
                "cumulative_nav": cumulative_nav,
                "nav_date": nav_date,
                "daily_change": daily_change,
                "one_month_return": one_month_return,
                "one_year_return": one_year_return,
                "since_inception_return": since_inception_return,
                "data_collection_time": datetime.now().isoformat(),
                "report_date": "2025-07-11"  # åŸºäºHTMLä¸­çš„å‡€å€¼æ—¥æœŸ
            }
            
            funds_data.append(fund_data)
            
        except Exception as e:
            # è·³è¿‡è§£æå¤±è´¥çš„è¡Œ
            continue
    
    print(f"âœ… æˆåŠŸè§£æ {len(funds_data)} åªåŸºé‡‘")
    return funds_data


def determine_fund_type(fund_name: str) -> str:
    """æ ¹æ®åŸºé‡‘åç§°åˆ¤æ–­åŸºé‡‘ç±»å‹"""
    
    if any(keyword in fund_name for keyword in ["è‚¡ç¥¨", "è¡Œä¸š", "ä¸»é¢˜", "ç²¾é€‰", "æˆé•¿", "ä»·å€¼"]):
        return "è‚¡ç¥¨å‹"
    elif any(keyword in fund_name for keyword in ["æ··åˆ", "é…ç½®", "ç­–ç•¥", "å‡è¡¡", "ç¨³å¥", "çµæ´»"]):
        return "æ··åˆå‹"
    elif any(keyword in fund_name for keyword in ["å€ºåˆ¸", "çº¯å€º", "é‡‘èå€º", "ä¿¡ç”¨å€º", "å¯è½¬å€º"]):
        return "å€ºåˆ¸å‹"
    elif any(keyword in fund_name for keyword in ["æŒ‡æ•°", "ETF", "300", "500", "åˆ›ä¸šæ¿", "ç§‘åˆ›"]):
        return "æŒ‡æ•°å‹"
    elif any(keyword in fund_name for keyword in ["è´§å¸", "ç°é‡‘", "æ—¥å¢åˆ©", "å¤©å¤©"]):
        return "è´§å¸å‹"
    elif any(keyword in fund_name for keyword in ["QDII", "æµ·å¤–", "å…¨çƒ", "ç¾å›½", "æ¸¯è‚¡"]):
        return "QDII"
    elif any(keyword in fund_name for keyword in ["FOF", "åŸºé‡‘ä¸­çš„åŸºé‡‘"]):
        return "FOF"
    elif any(keyword in fund_name for keyword in ["REITs", "ä¸åŠ¨äº§", "æˆ¿åœ°äº§"]):
        return "REITs"
    else:
        # é»˜è®¤åˆ†ç±»é€»è¾‘
        if "å€º" in fund_name:
            return "å€ºåˆ¸å‹"
        elif any(keyword in fund_name for keyword in ["å¹³è¡¡", "æ”¶ç›Š", "å¢é•¿"]):
            return "æ··åˆå‹"
        else:
            return "å…¶ä»–"


def analyze_fund_distribution(funds_data: List[Dict]):
    """åˆ†æåŸºé‡‘åˆ†å¸ƒæƒ…å†µ"""
    
    print(f"\nğŸ“Š å¹³å®‰åŸºé‡‘äº§å“åˆ†æ")
    print("=" * 60)
    
    # åŸºé‡‘ç±»å‹åˆ†å¸ƒ
    type_stats = {}
    total_funds = len(funds_data)
    
    for fund in funds_data:
        fund_type = fund['fund_type']
        type_stats[fund_type] = type_stats.get(fund_type, 0) + 1
    
    print(f"ğŸ“ˆ åŸºé‡‘ç±»å‹åˆ†å¸ƒ (æ€»è®¡ {total_funds} åª):")
    for fund_type, count in sorted(type_stats.items(), key=lambda x: x[1], reverse=True):
        percentage = count / total_funds * 100
        print(f"  â€¢ {fund_type}: {count} åª ({percentage:.1f}%)")
    
    # å‡€å€¼åˆ†å¸ƒåˆ†æ
    valid_navs = [fund['unit_nav'] for fund in funds_data if fund['unit_nav'] is not None]
    if valid_navs:
        avg_nav = sum(valid_navs) / len(valid_navs)
        max_nav = max(valid_navs)
        min_nav = min(valid_navs)
        print(f"\nğŸ’° åŸºé‡‘å‡€å€¼åˆ†æ:")
        print(f"  â€¢ å¹³å‡å•ä½å‡€å€¼: {avg_nav:.4f}")
        print(f"  â€¢ æœ€é«˜å•ä½å‡€å€¼: {max_nav:.4f}")
        print(f"  â€¢ æœ€ä½å•ä½å‡€å€¼: {min_nav:.4f}")
    
    # æ”¶ç›Šç‡åˆ†æ
    valid_returns = [fund['since_inception_return'] for fund in funds_data 
                    if fund['since_inception_return'] is not None]
    if valid_returns:
        avg_return = sum(valid_returns) / len(valid_returns) * 100
        max_return = max(valid_returns) * 100
        min_return = min(valid_returns) * 100
        print(f"\nğŸ“ˆ æˆç«‹ä»¥æ¥æ”¶ç›Šç‡åˆ†æ:")
        print(f"  â€¢ å¹³å‡æ”¶ç›Šç‡: {avg_return:.2f}%")
        print(f"  â€¢ æœ€é«˜æ”¶ç›Šç‡: {max_return:.2f}%")
        print(f"  â€¢ æœ€ä½æ”¶ç›Šç‡: {min_return:.2f}%")
    
    # æ‰¾å‡ºè¡¨ç°æœ€å¥½çš„åŸºé‡‘
    best_performers = sorted(
        [fund for fund in funds_data if fund['since_inception_return'] is not None],
        key=lambda x: x['since_inception_return'],
        reverse=True
    )[:5]
    
    if best_performers:
        print(f"\nğŸ† æˆç«‹ä»¥æ¥æ”¶ç›Šç‡å‰5å:")
        for i, fund in enumerate(best_performers, 1):
            return_rate = fund['since_inception_return'] * 100
            print(f"  {i}. {fund['fund_name']} ({fund['fund_code']})")
            print(f"     æ”¶ç›Šç‡: {return_rate:.2f}% | å•ä½å‡€å€¼: {fund['unit_nav']:.4f}")


def save_complete_fund_data(funds_data: List[Dict]):
    """ä¿å­˜å®Œæ•´çš„åŸºé‡‘æ•°æ®"""
    
    # åˆ›å»ºç›®å½•
    data_dir = Path("data/analysis/pingan_2025")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ•°æ®
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    data_file = data_dir / f"pingan_funds_complete_2025_{timestamp}.json"
    
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(funds_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {data_file}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {data_file.stat().st_size / 1024:.1f} KB")
    
    return data_file


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¹³å®‰åŸºé‡‘å…¨é‡æ•°æ®è§£æ")
    print("=" * 70)
    
    try:
        # è§£æHTMLæ•°æ®
        funds_data = parse_pingan_funds_html()
        
        if not funds_data:
            print("âŒ æ²¡æœ‰è§£æåˆ°åŸºé‡‘æ•°æ®")
            return False
        
        # åˆ†æåŸºé‡‘åˆ†å¸ƒ
        analyze_fund_distribution(funds_data)
        
        # ä¿å­˜æ•°æ®
        data_file = save_complete_fund_data(funds_data)
        
        print(f"\nğŸ‰ è§£æå®Œæˆï¼")
        print(f"ğŸ“Š æ€»è®¡è§£æ: {len(funds_data)} åªåŸºé‡‘")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {data_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)