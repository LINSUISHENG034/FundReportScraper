#!/usr/bin/env python3
"""
å¹³å®‰åŸºé‡‘2025å¹´æ•°æ®è‡ªåŠ¨åŒ–æ”¶é›†è„šæœ¬
Automated data collection script for PingAn funds in 2025
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime, date
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.scrapers.fund_scraper import FundReportScraper
from src.parsers.xbrl_parser import XBRLParser
from src.services.data_persistence import FundDataPersistenceService
from src.storage.minio_client import MinIOClient
from src.core.logging import get_logger
from src.utils.rate_limiter import RateLimiter
from src.models.database import Fund, FundReport

logger = get_logger(__name__)


@dataclass
class FundAnalysisData:
    """åŸºé‡‘åˆ†ææ•°æ®ç»“æ„"""
    fund_code: str
    fund_name: str
    fund_company: str
    fund_type: str
    establishment_date: Optional[date]
    net_asset_value: Optional[float]
    unit_nav: Optional[float]
    total_return_ytd: Optional[float]
    annual_return: Optional[float]
    volatility: Optional[float]
    sharpe_ratio: Optional[float]
    max_drawdown: Optional[float]
    stock_allocation: Optional[float]
    bond_allocation: Optional[float]
    cash_allocation: Optional[float]
    top_holdings: List[Dict[str, Any]]
    industry_allocation: Dict[str, float]
    report_date: date
    data_collection_time: datetime


class PingAnFundCollector:
    """å¹³å®‰åŸºé‡‘æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ”¶é›†å™¨"""
        self.scraper = FundReportScraper()
        self.parser = XBRLParser()
        self.rate_limiter = RateLimiter(max_tokens=10, refill_rate=2.0)
        self.collected_funds = []
        
        # å¹³å®‰åŸºé‡‘å…¬å¸ç›¸å…³åŸºé‡‘ä»£ç 
        self.pingan_fund_codes = [
            # å¹³å®‰å¤§åå“ç‰Œ
            "000327",  # å¹³å®‰å¤§åæ·»åˆ©å€ºåˆ¸A
            "000328",  # å¹³å®‰å¤§åæ·»åˆ©å€ºåˆ¸C
            "001304",  # å¹³å®‰å¤§åè¡Œä¸šå…ˆé”‹æ··åˆ
            "001305",  # å¹³å®‰å¤§åæ™ºæ…§ä¸­å›½çµæ´»é…ç½®æ··åˆ
            "002295",  # å¹³å®‰å¤§åæ–°é‘«å…ˆé”‹æ··åˆA
            "002296",  # å¹³å®‰å¤§åæ–°é‘«å…ˆé”‹æ··åˆC
            "003336",  # å¹³å®‰å¤§åé¼å¼˜æ··åˆA
            "003337",  # å¹³å®‰å¤§åé¼å¼˜æ··åˆC
            "005447",  # å¹³å®‰ä¸­è¯å…‰ä¼äº§ä¸šæŒ‡æ•°A
            "005448",  # å¹³å®‰ä¸­è¯å…‰ä¼äº§ä¸šæŒ‡æ•°C
            "006930",  # å¹³å®‰æƒ ç›ˆçº¯å€ºå€ºåˆ¸A
            "006931",  # å¹³å®‰æƒ ç›ˆçº¯å€ºå€ºåˆ¸C
            "008322",  # å¹³å®‰æ ¸å¿ƒä¼˜åŠ¿æ··åˆA
            "008323",  # å¹³å®‰æ ¸å¿ƒä¼˜åŠ¿æ··åˆC
            "009878",  # å¹³å®‰å¢åˆ©å…­ä¸ªæœˆå®šæœŸå¼€æ”¾å€ºåˆ¸A
            "009879",  # å¹³å®‰å¢åˆ©å…­ä¸ªæœˆå®šæœŸå¼€æ”¾å€ºåˆ¸C
        ]
        
        logger.info("ping_an_collector.initialized", fund_count=len(self.pingan_fund_codes))
    
    async def collect_single_fund_data(self, fund_code: str) -> Optional[FundAnalysisData]:
        """
        æ”¶é›†å•ä¸ªåŸºé‡‘æ•°æ®
        
        Args:
            fund_code: åŸºé‡‘ä»£ç 
            
        Returns:
            åŸºé‡‘åˆ†ææ•°æ®
        """
        try:
            # é™æµæ§åˆ¶
            await self.rate_limiter.acquire()
            
            logger.info("collecting_fund_data", fund_code=fund_code)
            
            # è·å–åŸºé‡‘æŠ¥å‘Šåˆ—è¡¨
            reports = await self.scraper.get_fund_reports(fund_code)
            if not reports:
                logger.warning("no_reports_found", fund_code=fund_code)
                return None
            
            # è·å–æœ€æ–°çš„2025å¹´æŠ¥å‘Š
            latest_2025_report = None
            for report in reports:
                if report['report_date'].year == 2025:
                    if latest_2025_report is None or report['report_date'] > latest_2025_report['report_date']:
                        latest_2025_report = report
            
            if not latest_2025_report:
                logger.warning("no_2025_report_found", fund_code=fund_code)
                return None
            
            # ä¸‹è½½å¹¶è§£ææŠ¥å‘Š
            report_content = await self.scraper.download_report(latest_2025_report['download_url'])
            if not report_content:
                logger.error("failed_to_download_report", fund_code=fund_code)
                return None
            
            # è§£æXBRLæ•°æ®
            self.parser.load_from_content(report_content.decode('utf-8'))
            
            fund_info = self.parser.extract_fund_basic_info()
            asset_allocation = self.parser.extract_asset_allocation()
            top_holdings = self.parser.extract_top_holdings()
            industry_allocation = self.parser.extract_industry_allocation()
            
            if not fund_info:
                logger.error("failed_to_parse_fund_info", fund_code=fund_code)
                return None
            
            # æ„å»ºåˆ†ææ•°æ®
            analysis_data = FundAnalysisData(
                fund_code=fund_info.fund_code,
                fund_name=fund_info.fund_name,
                fund_company="å¹³å®‰åŸºé‡‘ç®¡ç†æœ‰é™å…¬å¸",
                fund_type=self._determine_fund_type(fund_info.fund_name),
                establishment_date=None,  # éœ€è¦ä»å…¶ä»–æ•°æ®æºè·å–
                net_asset_value=float(fund_info.net_asset_value) if fund_info.net_asset_value else None,
                unit_nav=float(fund_info.unit_nav) if fund_info.unit_nav else None,
                total_return_ytd=None,  # éœ€è¦è®¡ç®—
                annual_return=None,  # éœ€è¦è®¡ç®—
                volatility=None,  # éœ€è¦è®¡ç®—
                sharpe_ratio=None,  # éœ€è¦è®¡ç®—
                max_drawdown=None,  # éœ€è¦è®¡ç®—
                stock_allocation=float(asset_allocation.stock_ratio) if asset_allocation and asset_allocation.stock_ratio else None,
                bond_allocation=float(asset_allocation.bond_ratio) if asset_allocation and asset_allocation.bond_ratio else None,
                cash_allocation=float(asset_allocation.cash_ratio) if asset_allocation and asset_allocation.cash_ratio else None,
                top_holdings=[asdict(holding) for holding in top_holdings] if top_holdings else [],
                industry_allocation={ind.industry_name: float(ind.allocation_ratio) for ind in industry_allocation} if industry_allocation else {},
                report_date=latest_2025_report['report_date'],
                data_collection_time=datetime.now()
            )
            
            logger.info("fund_data_collected", fund_code=fund_code, fund_name=fund_info.fund_name)
            return analysis_data
            
        except Exception as e:
            logger.error("fund_collection_failed", fund_code=fund_code, error=str(e))
            return None
    
    def _determine_fund_type(self, fund_name: str) -> str:
        """æ ¹æ®åŸºé‡‘åç§°åˆ¤æ–­åŸºé‡‘ç±»å‹"""
        if "è‚¡ç¥¨" in fund_name or "æŒ‡æ•°" in fund_name:
            return "è‚¡ç¥¨å‹"
        elif "å€ºåˆ¸" in fund_name or "çº¯å€º" in fund_name:
            return "å€ºåˆ¸å‹"
        elif "æ··åˆ" in fund_name:
            return "æ··åˆå‹"
        elif "è´§å¸" in fund_name:
            return "è´§å¸å‹"
        else:
            return "å…¶ä»–"
    
    async def collect_all_pingan_funds(self) -> List[FundAnalysisData]:
        """æ”¶é›†æ‰€æœ‰å¹³å®‰åŸºé‡‘æ•°æ®"""
        logger.info("starting_pingan_fund_collection", total_funds=len(self.pingan_fund_codes))
        
        collected_data = []
        
        for fund_code in self.pingan_fund_codes:
            try:
                fund_data = await self.collect_single_fund_data(fund_code)
                if fund_data:
                    collected_data.append(fund_data)
                    self.collected_funds.append(fund_data)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error("fund_collection_error", fund_code=fund_code, error=str(e))
                continue
        
        logger.info("pingan_fund_collection_completed", 
                   total_requested=len(self.pingan_fund_codes),
                   successfully_collected=len(collected_data))
        
        return collected_data
    
    def save_collected_data(self, data: List[FundAnalysisData], file_path: str) -> bool:
        """ä¿å­˜æ”¶é›†çš„æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            serializable_data = []
            for fund_data in data:
                fund_dict = asdict(fund_data)
                # å¤„ç†æ—¥æœŸåºåˆ—åŒ–
                if fund_dict['establishment_date']:
                    fund_dict['establishment_date'] = fund_dict['establishment_date'].isoformat()
                fund_dict['report_date'] = fund_dict['report_date'].isoformat()
                fund_dict['data_collection_time'] = fund_dict['data_collection_time'].isoformat()
                serializable_data.append(fund_dict)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(serializable_data, f, ensure_ascii=False, indent=2)
            
            logger.info("data_saved_successfully", file_path=file_path, record_count=len(data))
            return True
            
        except Exception as e:
            logger.error("data_save_failed", file_path=file_path, error=str(e))
            return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¹³å®‰åŸºé‡‘2025å¹´æ•°æ®è‡ªåŠ¨åŒ–æ”¶é›†")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("data/analysis/pingan_2025")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    collector = PingAnFundCollector()
    
    try:
        # æ”¶é›†å¹³å®‰åŸºé‡‘æ•°æ®
        print("\nğŸ“Š å¼€å§‹æ”¶é›†å¹³å®‰åŸºé‡‘2025å¹´æ•°æ®...")
        pingan_data = await collector.collect_all_pingan_funds()
        
        if not pingan_data:
            print("âŒ æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•å¹³å®‰åŸºé‡‘æ•°æ®")
            return False
        
        # ä¿å­˜æ•°æ®
        data_file = output_dir / f"pingan_funds_2025_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        if collector.save_collected_data(pingan_data, str(data_file)):
            print(f"âœ… å¹³å®‰åŸºé‡‘æ•°æ®å·²ä¿å­˜è‡³: {data_file}")
        
        # è¾“å‡ºæ”¶é›†ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ•°æ®æ”¶é›†ç»Ÿè®¡:")
        print(f"  â€¢ ç›®æ ‡åŸºé‡‘æ•°é‡: {len(collector.pingan_fund_codes)}")
        print(f"  â€¢ æˆåŠŸæ”¶é›†æ•°é‡: {len(pingan_data)}")
        print(f"  â€¢ æ”¶é›†æˆåŠŸç‡: {len(pingan_data)/len(collector.pingan_fund_codes)*100:.1f}%")
        
        # æŒ‰åŸºé‡‘ç±»å‹åˆ†ç±»ç»Ÿè®¡
        type_stats = {}
        for fund in pingan_data:
            fund_type = fund.fund_type
            type_stats[fund_type] = type_stats.get(fund_type, 0) + 1
        
        print(f"\nğŸ“Š åŸºé‡‘ç±»å‹åˆ†å¸ƒ:")
        for fund_type, count in type_stats.items():
            print(f"  â€¢ {fund_type}: {count} åª")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ”¶é›†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        logger.error("main_collection_error", error=str(e))
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)