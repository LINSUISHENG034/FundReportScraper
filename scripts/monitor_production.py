#!/usr/bin/env python3
"""
ç”Ÿäº§ç¯å¢ƒç›‘æ§è„šæœ¬
Production Monitoring Script

æŒç»­ç›‘æ§ç”Ÿäº§ç¯å¢ƒçš„è¿è¡ŒçŠ¶æ€ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ
"""

import os
import sys
import time
import json
import psutil
import requests
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import structlog

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.config import get_settings

class Color:
    """é¢œè‰²å¸¸é‡"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    PURPLE = '\033[0;35m'
    CYAN = '\033[0;36m'
    NC = '\033[0m'  # No Color

class ProductionMonitor:
    """ç”Ÿäº§ç¯å¢ƒç›‘æ§å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.settings = get_settings()
        self.monitoring_data = []
        self.alert_thresholds = {
            'cpu_usage': 80.0,           # CPUä½¿ç”¨ç‡é˜ˆå€¼ (%)
            'memory_usage': 85.0,        # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼ (%)
            'disk_usage': 90.0,          # ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼ (%)
            'api_response_time': 5.0,    # APIå“åº”æ—¶é—´é˜ˆå€¼ (ç§’)
            'error_rate': 5.0,           # é”™è¯¯ç‡é˜ˆå€¼ (%)
            'queue_length': 100          # ä»»åŠ¡é˜Ÿåˆ—é•¿åº¦é˜ˆå€¼
        }
        
        # é…ç½®ç»“æ„åŒ–æ—¥å¿—
        structlog.configure(
            processors=[
                structlog.stdlib.filter_by_level,
                structlog.stdlib.add_logger_name,
                structlog.stdlib.add_log_level,
                structlog.stdlib.PositionalArgumentsFormatter(),
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                structlog.processors.UnicodeDecoder(),
                structlog.processors.JSONRenderer()
            ],
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            wrapper_class=structlog.stdlib.BoundLogger,
            cache_logger_on_first_use=True,
        )
        
        self.logger = structlog.get_logger("production_monitor")
        
    def log(self, level: str, message: str, **kwargs):
        """è®°å½•æ—¥å¿—"""
        colors = {
            'INFO': Color.BLUE,
            'SUCCESS': Color.GREEN,
            'WARNING': Color.YELLOW,
            'ERROR': Color.RED,
            'ALERT': Color.RED,
            'TITLE': Color.PURPLE
        }
        color = colors.get(level, Color.NC)
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"{color}[{timestamp} {level}]{Color.NC} {message}")
        
        # åŒæ—¶è®°å½•åˆ°ç»“æ„åŒ–æ—¥å¿—
        log_method = getattr(self.logger, level.lower(), self.logger.info)
        log_method(message, **kwargs)
    
    def check_system_resources(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # ç£ç›˜ä½¿ç”¨æƒ…å†µ
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            
            # ç½‘ç»œIO
            network = psutil.net_io_counters()
            
            resource_data = {
                'timestamp': datetime.now().isoformat(),
                'cpu_usage': cpu_percent,
                'memory': {
                    'total': memory.total,
                    'available': memory.available,
                    'used': memory.used,
                    'percent': memory_percent
                },
                'disk': {
                    'total': disk.total,
                    'used': disk.used,
                    'free': disk.free,
                    'percent': disk_percent
                },
                'network': {
                    'bytes_sent': network.bytes_sent,
                    'bytes_recv': network.bytes_recv,
                    'packets_sent': network.packets_sent,
                    'packets_recv': network.packets_recv
                }
            }
            
            # æ£€æŸ¥èµ„æºä½¿ç”¨ç‡å‘Šè­¦
            alerts = []
            if cpu_percent > self.alert_thresholds['cpu_usage']:
                alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%")
                self.log('ALERT', f"ğŸš¨ CPUä½¿ç”¨ç‡å‘Šè­¦: {cpu_percent:.1f}%")
            
            if memory_percent > self.alert_thresholds['memory_usage']:
                alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_percent:.1f}%")
                self.log('ALERT', f"ğŸš¨ å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦: {memory_percent:.1f}%")
            
            if disk_percent > self.alert_thresholds['disk_usage']:
                alerts.append(f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_percent:.1f}%")
                self.log('ALERT', f"ğŸš¨ ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦: {disk_percent:.1f}%")
            
            resource_data['alerts'] = alerts
            
            if not alerts:
                self.log('SUCCESS', 
                    f"ç³»ç»Ÿèµ„æºæ­£å¸¸ - CPU: {cpu_percent:.1f}%, "
                    f"å†…å­˜: {memory_percent:.1f}%, "
                    f"ç£ç›˜: {disk_percent:.1f}%"
                )
            
            return resource_data
            
        except Exception as e:
            self.log('ERROR', f"ç³»ç»Ÿèµ„æºæ£€æŸ¥å¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def check_docker_services(self) -> Dict[str, Any]:
        """æ£€æŸ¥DockeræœåŠ¡çŠ¶æ€"""
        try:
            result = subprocess.run(
                ['docker-compose', '-f', 'docker-compose.prod.yml', 'ps', '--format', 'json'],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # è§£æJSONè¾“å‡º
                services_data = []
                for line in result.stdout.strip().split('\n'):
                    if line:
                        try:
                            service = json.loads(line)
                            services_data.append(service)
                        except json.JSONDecodeError:
                            continue
                
                # åˆ†ææœåŠ¡çŠ¶æ€
                service_status = {}
                total_services = len(services_data)
                running_services = 0
                
                for service in services_data:
                    service_name = service.get('Service', 'unknown')
                    service_state = service.get('State', 'unknown')
                    
                    service_status[service_name] = {
                        'state': service_state,
                        'status': service.get('Status', ''),
                        'ports': service.get('Ports', ''),
                        'running': service_state == 'running'
                    }
                    
                    if service_state == 'running':
                        running_services += 1
                        self.log('SUCCESS', f"âœ“ {service_name} æœåŠ¡è¿è¡Œæ­£å¸¸")
                    else:
                        self.log('ERROR', f"âœ— {service_name} æœåŠ¡çŠ¶æ€å¼‚å¸¸: {service_state}")
                
                docker_data = {
                    'timestamp': datetime.now().isoformat(),
                    'total_services': total_services,
                    'running_services': running_services,
                    'service_status': service_status,
                    'health_rate': (running_services / total_services * 100) if total_services > 0 else 0
                }
                
                if running_services < total_services:
                    self.log('ALERT', f"ğŸš¨ æœåŠ¡å¼‚å¸¸å‘Šè­¦: {running_services}/{total_services} æœåŠ¡è¿è¡Œä¸­")
                
                return docker_data
            else:
                self.log('ERROR', f"DockeræœåŠ¡æ£€æŸ¥å¤±è´¥: {result.stderr}")
                return {'error': result.stderr}
                
        except Exception as e:
            self.log('ERROR', f"DockeræœåŠ¡æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return {'error': str(e)}
    
    def check_api_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥APIæœåŠ¡å¥åº·çŠ¶å†µ"""
        api_data = {
            'timestamp': datetime.now().isoformat(),
            'endpoints': {},
            'overall_health': True,
            'response_times': []
        }
        
        # æµ‹è¯•çš„APIç«¯ç‚¹
        endpoints = [
            ('/health', 'å¥åº·æ£€æŸ¥'),
            ('/api/v1/funds/', 'åŸºé‡‘åˆ—è¡¨'),
            ('/api/v1/reports/', 'æŠ¥å‘Šåˆ—è¡¨'),
            ('/api/v1/tasks/', 'ä»»åŠ¡åˆ—è¡¨'),
            ('/api/v1/tasks/stats/summary', 'ä»»åŠ¡ç»Ÿè®¡')
        ]
        
        for endpoint, description in endpoints:
            try:
                start_time = time.time()
                response = requests.get(
                    f"http://localhost:{self.settings.API_PORT}{endpoint}",
                    timeout=10
                )
                response_time = time.time() - start_time
                
                endpoint_status = {
                    'status_code': response.status_code,
                    'response_time': response_time,
                    'healthy': response.status_code == 200,
                    'description': description
                }
                
                if response.status_code == 200:
                    self.log('SUCCESS', f"âœ“ {description} ({endpoint}): {response_time:.3f}s")
                else:
                    self.log('ERROR', f"âœ— {description} ({endpoint}): {response.status_code}")
                    api_data['overall_health'] = False
                
                # æ£€æŸ¥å“åº”æ—¶é—´å‘Šè­¦
                if response_time > self.alert_thresholds['api_response_time']:
                    self.log('ALERT', f"ğŸš¨ APIå“åº”æ—¶é—´å‘Šè­¦: {endpoint} - {response_time:.3f}s")
                    endpoint_status['slow_response'] = True
                
                api_data['endpoints'][endpoint] = endpoint_status
                api_data['response_times'].append(response_time)
                
            except requests.RequestException as e:
                self.log('ERROR', f"âœ— {description} ({endpoint}): è¯·æ±‚å¤±è´¥ - {str(e)}")
                api_data['endpoints'][endpoint] = {
                    'error': str(e),
                    'healthy': False,
                    'description': description
                }
                api_data['overall_health'] = False
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if api_data['response_times']:
            api_data['avg_response_time'] = sum(api_data['response_times']) / len(api_data['response_times'])
            api_data['max_response_time'] = max(api_data['response_times'])
        
        return api_data
    
    def check_database_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
        try:
            # é€šè¿‡Dockeræ£€æŸ¥PostgreSQLçŠ¶æ€
            result = subprocess.run(
                ['docker-compose', '-f', 'docker-compose.prod.yml', 'exec', '-T', 'postgres', 
                 'psql', '-U', 'funduser_prod', '-d', 'fundreport_prod', '-c', 
                 'SELECT COUNT(*) as total_funds FROM funds; SELECT COUNT(*) as total_reports FROM reports;'],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                self.log('SUCCESS', "âœ“ æ•°æ®åº“è¿æ¥æ­£å¸¸")
                
                # ç®€å•è§£ææ•°æ®ç»Ÿè®¡
                lines = result.stdout.strip().split('\n')
                db_data = {
                    'timestamp': datetime.now().isoformat(),
                    'connected': True,
                    'status': 'healthy'
                }
                
                # å°è¯•è§£ææ•°æ®è¡Œæ•°ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                try:
                    for line in lines:
                        if line.strip().isdigit():
                            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”è¯¥æ›´ç²¾ç¡®åœ°è§£æ
                            break
                except:
                    pass
                
                return db_data
            else:
                self.log('ERROR', f"âœ— æ•°æ®åº“è¿æ¥å¤±è´¥: {result.stderr}")
                return {
                    'timestamp': datetime.now().isoformat(),
                    'connected': False,
                    'error': result.stderr
                }
                
        except Exception as e:
            self.log('ERROR', f"æ•°æ®åº“çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return {
                'timestamp': datetime.now().isoformat(),
                'connected': False,
                'error': str(e)
            }
    
    def check_celery_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥Celeryä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€"""
        try:
            # é€šè¿‡Redisæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—
            result = subprocess.run(
                ['docker-compose', '-f', 'docker-compose.prod.yml', 'exec', '-T', 'redis',
                 'redis-cli', 'LLEN', 'celery'],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            celery_data = {
                'timestamp': datetime.now().isoformat()
            }
            
            if result.returncode == 0:
                queue_length = int(result.stdout.strip()) if result.stdout.strip().isdigit() else 0
                celery_data.update({
                    'queue_length': queue_length,
                    'queue_healthy': True
                })
                
                if queue_length > self.alert_thresholds['queue_length']:
                    self.log('ALERT', f"ğŸš¨ ä»»åŠ¡é˜Ÿåˆ—å‘Šè­¦: {queue_length} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
                    celery_data['queue_alert'] = True
                else:
                    self.log('SUCCESS', f"âœ“ ä»»åŠ¡é˜Ÿåˆ—æ­£å¸¸: {queue_length} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
                
            else:
                self.log('ERROR', f"âœ— ä»»åŠ¡é˜Ÿåˆ—æ£€æŸ¥å¤±è´¥: {result.stderr}")
                celery_data.update({
                    'queue_healthy': False,
                    'error': result.stderr
                })
            
            return celery_data
            
        except Exception as e:
            self.log('ERROR', f"CeleryçŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return {
                'timestamp': datetime.now().isoformat(),
                'queue_healthy': False,
                'error': str(e)
            }
    
    def check_log_files(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¥å¿—æ–‡ä»¶çŠ¶æ€"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'log_files': {}
        }
        
        # æ£€æŸ¥çš„æ—¥å¿—æ–‡ä»¶
        log_files = [
            'logs/api.log',
            'logs/celery_worker.log',
            'logs/celery_beat.log'
        ]
        
        for log_file in log_files:
            log_path = self.project_root / log_file
            
            if log_path.exists():
                try:
                    stat = log_path.stat()
                    file_size = stat.st_size
                    modified_time = datetime.fromtimestamp(stat.st_mtime)
                    
                    # æ£€æŸ¥æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
                    recent_errors = 0
                    try:
                        with open(log_path, 'r') as f:
                            # è¯»å–æœ€å1000è¡Œ
                            lines = f.readlines()[-1000:]
                            for line in lines:
                                if 'ERROR' in line.upper() or 'CRITICAL' in line.upper():
                                    recent_errors += 1
                    except:
                        pass
                    
                    log_data['log_files'][log_file] = {
                        'exists': True,
                        'size': file_size,
                        'modified': modified_time.isoformat(),
                        'recent_errors': recent_errors
                    }
                    
                    if recent_errors > 10:
                        self.log('ALERT', f"ğŸš¨ æ—¥å¿—é”™è¯¯å‘Šè­¦: {log_file} æœ€è¿‘æœ‰ {recent_errors} ä¸ªé”™è¯¯")
                    else:
                        self.log('SUCCESS', f"âœ“ {log_file}: {file_size} bytes, {recent_errors} é”™è¯¯")
                        
                except Exception as e:
                    log_data['log_files'][log_file] = {
                        'exists': True,
                        'error': str(e)
                    }
            else:
                log_data['log_files'][log_file] = {
                    'exists': False
                }
                self.log('WARNING', f"âš  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        
        return log_data
    
    def generate_monitoring_report(self, monitoring_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        timestamp = datetime.now()
        
        # è®¡ç®—æ•´ä½“å¥åº·åˆ†æ•°
        health_score = 100
        alerts = []
        
        # ç³»ç»Ÿèµ„æºæ£€æŸ¥
        if 'system' in monitoring_data and 'alerts' in monitoring_data['system']:
            health_score -= len(monitoring_data['system']['alerts']) * 10
            alerts.extend(monitoring_data['system']['alerts'])
        
        # DockeræœåŠ¡æ£€æŸ¥
        if 'docker' in monitoring_data:
            health_rate = monitoring_data['docker'].get('health_rate', 0)
            if health_rate < 100:
                health_score -= (100 - health_rate)
                alerts.append(f"DockeræœåŠ¡å¥åº·ç‡: {health_rate:.1f}%")
        
        # APIå¥åº·æ£€æŸ¥
        if 'api' in monitoring_data:
            if not monitoring_data['api'].get('overall_health', False):
                health_score -= 20
                alerts.append("APIæœåŠ¡å¼‚å¸¸")
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""# ç”Ÿäº§ç¯å¢ƒç›‘æ§æŠ¥å‘Š
## Production Environment Monitoring Report

**ç›‘æ§æ—¶é—´**: {timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**ç³»ç»Ÿå¥åº·åˆ†æ•°**: {max(health_score, 0)}/100  
**å‘Šè­¦æ•°é‡**: {len(alerts)}

---

## ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ

### æ•´ä½“çŠ¶æ€
"""
        
        if health_score >= 90:
            report_content += "âœ… **ç³»ç»ŸçŠ¶æ€ä¼˜ç§€** - æ‰€æœ‰ç»„ä»¶è¿è¡Œæ­£å¸¸\n"
        elif health_score >= 70:
            report_content += "âš ï¸ **ç³»ç»ŸçŠ¶æ€è‰¯å¥½** - å­˜åœ¨å°‘é‡é—®é¢˜éœ€è¦å…³æ³¨\n"
        elif health_score >= 50:
            report_content += "ğŸ”§ **ç³»ç»ŸçŠ¶æ€ä¸€èˆ¬** - å­˜åœ¨å¤šä¸ªé—®é¢˜éœ€è¦å¤„ç†\n"
        else:
            report_content += "ğŸš¨ **ç³»ç»ŸçŠ¶æ€ä¸¥é‡** - éœ€è¦ç«‹å³å¤„ç†ä¸¥é‡é—®é¢˜\n"
        
        # å‘Šè­¦æ‘˜è¦
        if alerts:
            report_content += f"\n### ğŸš¨ å½“å‰å‘Šè­¦\n"
            for alert in alerts:
                report_content += f"- {alert}\n"
        else:
            report_content += f"\n### âœ… æ— å‘Šè­¦\n"
        
        # è¯¦ç»†ç›‘æ§æ•°æ®
        if 'system' in monitoring_data:
            system_data = monitoring_data['system']
            report_content += f"""
---

## ğŸ’» ç³»ç»Ÿèµ„æº

- **CPUä½¿ç”¨ç‡**: {system_data.get('cpu_usage', 0):.1f}%
- **å†…å­˜ä½¿ç”¨ç‡**: {system_data.get('memory', {}).get('percent', 0):.1f}%
- **ç£ç›˜ä½¿ç”¨ç‡**: {system_data.get('disk', {}).get('percent', 0):.1f}%
- **å¯ç”¨å†…å­˜**: {system_data.get('memory', {}).get('available', 0) / (1024**3):.1f} GB
- **å¯ç”¨ç£ç›˜**: {system_data.get('disk', {}).get('free', 0) / (1024**3):.1f} GB
"""
        
        if 'docker' in monitoring_data:
            docker_data = monitoring_data['docker']
            report_content += f"""
---

## ğŸ³ DockeræœåŠ¡

- **è¿è¡ŒæœåŠ¡**: {docker_data.get('running_services', 0)}/{docker_data.get('total_services', 0)}
- **å¥åº·ç‡**: {docker_data.get('health_rate', 0):.1f}%

### æœåŠ¡çŠ¶æ€è¯¦æƒ…
"""
            
            for service, status in docker_data.get('service_status', {}).items():
                status_icon = "âœ…" if status.get('running', False) else "âŒ"
                report_content += f"- {status_icon} **{service}**: {status.get('state', 'unknown')}\n"
        
        if 'api' in monitoring_data:
            api_data = monitoring_data['api']
            report_content += f"""
---

## ğŸŒ APIæœåŠ¡

- **æ•´ä½“å¥åº·**: {"âœ… æ­£å¸¸" if api_data.get('overall_health', False) else "âŒ å¼‚å¸¸"}
- **å¹³å‡å“åº”æ—¶é—´**: {api_data.get('avg_response_time', 0):.3f}s
- **æœ€å¤§å“åº”æ—¶é—´**: {api_data.get('max_response_time', 0):.3f}s

### APIç«¯ç‚¹çŠ¶æ€
"""
            
            for endpoint, status in api_data.get('endpoints', {}).items():
                if 'error' in status:
                    report_content += f"- âŒ **{endpoint}**: é”™è¯¯ - {status['error']}\n"
                else:
                    status_icon = "âœ…" if status.get('healthy', False) else "âŒ"
                    response_time = status.get('response_time', 0)
                    report_content += f"- {status_icon} **{endpoint}**: {response_time:.3f}s\n"
        
        if 'database' in monitoring_data:
            db_data = monitoring_data['database']
            report_content += f"""
---

## ğŸ—„ï¸ æ•°æ®åº“

- **è¿æ¥çŠ¶æ€**: {"âœ… æ­£å¸¸" if db_data.get('connected', False) else "âŒ å¼‚å¸¸"}
- **æ•°æ®åº“çŠ¶æ€**: {db_data.get('status', 'æœªçŸ¥')}
"""
        
        if 'celery' in monitoring_data:
            celery_data = monitoring_data['celery']
            report_content += f"""
---

## âš™ï¸ ä»»åŠ¡é˜Ÿåˆ—

- **é˜Ÿåˆ—çŠ¶æ€**: {"âœ… æ­£å¸¸" if celery_data.get('queue_healthy', False) else "âŒ å¼‚å¸¸"}
- **å¾…å¤„ç†ä»»åŠ¡**: {celery_data.get('queue_length', 0)} ä¸ª
"""
        
        report_content += f"""
---

## ğŸ“‹ å»ºè®®è¡ŒåŠ¨

### ç«‹å³å¤„ç† (å¥åº·åˆ†æ•° < 70)
"""
        
        if health_score < 70:
            if health_score < 50:
                report_content += "1. ğŸš¨ **ç«‹å³æ£€æŸ¥ç³»ç»ŸçŠ¶æ€** - å¥åº·åˆ†æ•°è¿‡ä½\n"
                report_content += "2. ğŸ”§ **ä¼˜å…ˆå¤„ç†å‘Šè­¦é¡¹ç›®** - æ ¹æ®å‘Šè­¦ä¿¡æ¯æ’æŸ¥é—®é¢˜\n"
                report_content += "3. ğŸ“ **è”ç³»æŠ€æœ¯æ”¯æŒ** - å¦‚éœ€å¸®åŠ©è¯·åŠæ—¶è”ç³»\n"
            else:
                report_content += "1. âš ï¸ **å…³æ³¨å‘Šè­¦ä¿¡æ¯** - å¤„ç†å½“å‰å‘Šè­¦é¡¹ç›®\n"
                report_content += "2. ğŸ” **åˆ†ææ€§èƒ½æ•°æ®** - è¯†åˆ«æ½œåœ¨ç“¶é¢ˆ\n"
                report_content += "3. ğŸ“ˆ **ä¼˜åŒ–ç³»ç»Ÿé…ç½®** - æ ¹æ®ç›‘æ§æ•°æ®è°ƒæ•´\n"
        else:
            report_content += "- âœ… å½“å‰ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­ä¿æŒç›‘æ§\n"
        
        report_content += f"""
### å®šæœŸç»´æŠ¤
1. **æ—¥å¿—æ¸…ç†**: å®šæœŸæ¸…ç†è¿‡å¤§çš„æ—¥å¿—æ–‡ä»¶
2. **èµ„æºç›‘æ§**: æŒç»­å…³æ³¨CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µ
3. **æœåŠ¡æ£€æŸ¥**: ç¡®ä¿æ‰€æœ‰DockeræœåŠ¡æ­£å¸¸è¿è¡Œ
4. **æ•°æ®å¤‡ä»½**: å®šæœŸæ‰§è¡Œæ•°æ®åº“å’Œæ–‡ä»¶å¤‡ä»½

---

## ğŸ“ è”ç³»ä¿¡æ¯

**ç›‘æ§è´Ÿè´£äºº**: è¿ç»´å›¢é˜Ÿ  
**æŠ€æœ¯æ”¯æŒ**: åŸºé‡‘æŠ¥å‘Šå¹³å°å¼€å‘ç»„  
**ç´§æ€¥è”ç³»**: 7x24å°æ—¶å€¼ç­ç”µè¯  

---

**ç›‘æ§çŠ¶æ€**: å®æ—¶ç›‘æ§ä¸­  
**ä¸‹æ¬¡æ£€æŸ¥**: {(timestamp + timedelta(minutes=5)).strftime('%H:%M:%S')}  
**æŠ¥å‘Šé¢‘ç‡**: æ¯5åˆ†é’Ÿ
"""
        
        return report_content
    
    def run_single_check(self) -> Dict[str, Any]:
        """è¿è¡Œå•æ¬¡ç›‘æ§æ£€æŸ¥"""
        self.log('INFO', "å¼€å§‹ç”Ÿäº§ç¯å¢ƒç›‘æ§æ£€æŸ¥...")
        
        monitoring_data = {}
        
        # ç³»ç»Ÿèµ„æºæ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥ç³»ç»Ÿèµ„æº...")
        monitoring_data['system'] = self.check_system_resources()
        
        # DockeræœåŠ¡æ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥DockeræœåŠ¡...")
        monitoring_data['docker'] = self.check_docker_services()
        
        # APIå¥åº·æ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥APIæœåŠ¡...")
        monitoring_data['api'] = self.check_api_health()
        
        # æ•°æ®åº“çŠ¶æ€æ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥æ•°æ®åº“çŠ¶æ€...")
        monitoring_data['database'] = self.check_database_status()
        
        # Celeryä»»åŠ¡é˜Ÿåˆ—æ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—...")
        monitoring_data['celery'] = self.check_celery_status()
        
        # æ—¥å¿—æ–‡ä»¶æ£€æŸ¥
        self.log('INFO', "æ£€æŸ¥æ—¥å¿—æ–‡ä»¶...")
        monitoring_data['logs'] = self.check_log_files()
        
        # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
        report_content = self.generate_monitoring_report(monitoring_data)
        
        # ä¿å­˜ç›‘æ§æ•°æ®
        monitoring_data['timestamp'] = datetime.now().isoformat()
        monitoring_data['report_content'] = report_content
        
        return monitoring_data
    
    def run_continuous_monitoring(self, interval: int = 300, duration: Optional[int] = None):
        """è¿è¡ŒæŒç»­ç›‘æ§"""
        self.log('TITLE', '=' * 60)
        self.log('TITLE', 'ç”Ÿäº§ç¯å¢ƒæŒç»­ç›‘æ§å¼€å§‹')
        self.log('TITLE', f'ç›‘æ§é—´éš”: {interval}ç§’, æŒç»­æ—¶é—´: {"æ— é™åˆ¶" if duration is None else f"{duration}ç§’"}')
        self.log('TITLE', '=' * 60)
        
        start_time = time.time()
        check_count = 0
        
        try:
            while True:
                check_count += 1
                self.log('INFO', f"\nç¬¬ {check_count} æ¬¡ç›‘æ§æ£€æŸ¥ (è¿è¡Œæ—¶é—´: {int(time.time() - start_time)}ç§’)")
                
                # æ‰§è¡Œç›‘æ§æ£€æŸ¥
                monitoring_data = self.run_single_check()
                self.monitoring_data.append(monitoring_data)
                
                # ä¿å­˜ç›‘æ§æ•°æ®åˆ°æ–‡ä»¶
                data_file = self.project_root / f"logs/monitoring_{datetime.now().strftime('%Y%m%d')}.jsonl"
                data_file.parent.mkdir(exist_ok=True)
                
                with open(data_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(monitoring_data, ensure_ascii=False) + '\n')
                
                # å¦‚æœæœ‰å‘Šè­¦ï¼Œä¿å­˜å‘Šè­¦æŠ¥å‘Š
                if 'system' in monitoring_data and monitoring_data['system'].get('alerts'):
                    alert_file = self.project_root / f"reports/ç›‘æ§å‘Šè­¦_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                    alert_file.parent.mkdir(exist_ok=True)
                    
                    with open(alert_file, 'w', encoding='utf-8') as f:
                        f.write(monitoring_data['report_content'])
                    
                    self.log('ALERT', f"å‘Šè­¦æŠ¥å‘Šå·²ä¿å­˜: {alert_file}")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æŒç»­æ—¶é—´é™åˆ¶
                if duration and (time.time() - start_time) >= duration:
                    self.log('INFO', f"ç›‘æ§æŒç»­æ—¶é—´è¾¾åˆ°é™åˆ¶ ({duration}ç§’)ï¼Œåœæ­¢ç›‘æ§")
                    break
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                self.log('INFO', f"ä¸‹æ¬¡æ£€æŸ¥å°†åœ¨ {interval} ç§’åå¼€å§‹...")
                time.sleep(interval)
                
        except KeyboardInterrupt:
            self.log('WARNING', '\nç›‘æ§è¢«ç”¨æˆ·ä¸­æ–­')
        except Exception as e:
            self.log('ERROR', f'ç›‘æ§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}')
        
        # ç”Ÿæˆç›‘æ§æ‘˜è¦
        total_time = time.time() - start_time
        self.log('INFO', f"\nç›‘æ§ç»“æŸ - æ€»æ—¶é—´: {int(total_time)}ç§’, æ£€æŸ¥æ¬¡æ•°: {check_count}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”Ÿäº§ç¯å¢ƒç›‘æ§è„šæœ¬')
    parser.add_argument('--interval', type=int, default=300, help='ç›‘æ§é—´éš”(ç§’) (é»˜è®¤: 300)')
    parser.add_argument('--duration', type=int, help='ç›‘æ§æŒç»­æ—¶é—´(ç§’) (é»˜è®¤: æ— é™åˆ¶)')
    parser.add_argument('--single', action='store_true', help='åªè¿è¡Œå•æ¬¡æ£€æŸ¥')
    
    args = parser.parse_args()
    
    monitor = ProductionMonitor()
    
    try:
        if args.single:
            # å•æ¬¡ç›‘æ§æ£€æŸ¥
            result = monitor.run_single_check()
            
            # è¾“å‡ºç®€è¦ç»“æœ
            print("\n" + "="*50)
            print("ç›‘æ§æ£€æŸ¥å®Œæˆ")
            print("="*50)
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = monitor.project_root / f"reports/ç›‘æ§æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            report_file.parent.mkdir(exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(result['report_content'])
            
            print(f"ç›‘æ§æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
            sys.exit(0)
        else:
            # æŒç»­ç›‘æ§
            monitor.run_continuous_monitoring(args.interval, args.duration)
            sys.exit(0)
            
    except KeyboardInterrupt:
        monitor.log('WARNING', '\nç›‘æ§è¢«ç”¨æˆ·ä¸­æ–­')
        sys.exit(1)
    except Exception as e:
        monitor.log('ERROR', f'\nç›‘æ§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}')
        sys.exit(2)

if __name__ == '__main__':
    main()